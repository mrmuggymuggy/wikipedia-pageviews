version: '2'
#env: source from parent taskfile
#vars: source from parent taskfile
env:
  REMOTE_DAG_FOLDER: /usr/local/airflow
  DAG_NAME: wiki_pageviews_batch_job

tasks:

  backfill:
    summary: |
      When run locally, you need to specify environment variables
      eg. START_DATE=2020-01-22T02:00:00 END_DATE=2020-01-22T03:00:00 task dags:backfill

    cmds:
      - kubectl exec deploy/airflow -- airflow backfill $DAG_NAME --start_date "{{.START_DATE}}" --end_date "{{.END_DATE}}"    --rerun_failed_tasks
    vars:
      START_DATE:
        '{{default "2020-01-22T08:00:00" .START_DATE}}'
      END_DATE:
        '{{default "2020-01-22T09:00:00" .END_DATE}}'

  deploy:
    summary: |
      package and deploy the dag to Airflow
    dir: ./airflow-dags
    cmds:
      - mkdir -p dist
      - zip -r dist/$DAG_NAME.zip -MM $DAG_NAME.py
      - kubectl cp $(pwd)/dist/$DAG_NAME.zip $AIRFLOW_POD_NAME:$REMOTE_DAG_FOLDER/dags/$DAG_NAME.zip
    env:
      AIRFLOW_POD_NAME:
        sh: kubectl get pods -o jsonpath="{.items[0].metadata.name}" -l app.kubernetes.io/name=airflow || echo "no connection"

  undeploy:
    summary: |
      remove all zipped dag from airflow
    cmds:
      - kubectl exec deploy/airflow --  rm -rfv $REMOTE_DAG_FOLDER/dags/$DAG_NAME.zip
